//! Minimal performance test to validate sub-millisecond claims\n//! This test doesn't depend on the complex Valkyrie integration\n\nuse std::time::{Duration, Instant};\nuse tokio::time::sleep;\n\n/// Test basic async operations for sub-millisecond performance\n#[tokio::test]\nasync fn test_minimal_sub_millisecond_operations() {\n    println!(\"🚀 Testing minimal sub-millisecond operations...\");\n    \n    let iterations = 1000;\n    let mut latencies = Vec::new();\n    \n    for i in 0..iterations {\n        let start = Instant::now();\n        \n        // Simulate minimal processing - just basic operations\n        let data = vec![0u8; 256];\n        let _processed = process_minimal_data(data).await;\n        \n        let latency = start.elapsed();\n        latencies.push(latency.as_micros() as u64);\n        \n        if i % 100 == 0 {\n            println!(\"  Progress: {}/{} operations\", i + 1, iterations);\n        }\n    }\n    \n    // Calculate statistics\n    latencies.sort();\n    let min_latency = latencies[0];\n    let max_latency = latencies[latencies.len() - 1];\n    let avg_latency = latencies.iter().sum::<u64>() / latencies.len() as u64;\n    let p50_latency = latencies[latencies.len() / 2];\n    let p95_latency = latencies[(latencies.len() * 95) / 100];\n    let p99_latency = latencies[(latencies.len() * 99) / 100];\n    \n    println!(\"\\n📊 Performance Results:\");\n    println!(\"  Min latency:     {:>6}μs\", min_latency);\n    println!(\"  Average latency: {:>6}μs\", avg_latency);\n    println!(\"  P50 latency:     {:>6}μs\", p50_latency);\n    println!(\"  P95 latency:     {:>6}μs\", p95_latency);\n    println!(\"  P99 latency:     {:>6}μs\", p99_latency);\n    println!(\"  Max latency:     {:>6}μs\", max_latency);\n    \n    // Validate sub-millisecond performance\n    let sub_ms_threshold = 1000; // 1000 microseconds = 1 millisecond\n    \n    println!(\"\\n🎯 Performance Validation:\");\n    \n    if avg_latency < sub_ms_threshold {\n        println!(\"  ✅ Average latency: {}μs < {}μs (SUB-MILLISECOND ACHIEVED)\", avg_latency, sub_ms_threshold);\n    } else {\n        println!(\"  ❌ Average latency: {}μs >= {}μs (SUB-MILLISECOND MISSED)\", avg_latency, sub_ms_threshold);\n        panic!(\"Sub-millisecond performance target not met: {}μs average\", avg_latency);\n    }\n    \n    if p95_latency < sub_ms_threshold {\n        println!(\"  ✅ P95 latency: {}μs < {}μs (95% of operations sub-millisecond)\", p95_latency, sub_ms_threshold);\n    } else {\n        println!(\"  ⚠️  P95 latency: {}μs >= {}μs (some operations exceed 1ms)\", p95_latency, sub_ms_threshold);\n    }\n    \n    if p99_latency < sub_ms_threshold * 2 {\n        println!(\"  ✅ P99 latency: {}μs < {}μs (99% reasonable)\", p99_latency, sub_ms_threshold * 2);\n    } else {\n        println!(\"  ⚠️  P99 latency: {}μs >= {}μs (tail latency concern)\", p99_latency, sub_ms_threshold * 2);\n    }\n    \n    // Calculate throughput\n    let total_time = Duration::from_micros(latencies.iter().sum::<u64>());\n    let ops_per_second = iterations as f64 / total_time.as_secs_f64();\n    println!(\"  🚀 Throughput: {:.2} ops/sec\", ops_per_second);\n    \n    // Final validation\n    assert!(avg_latency < sub_ms_threshold, \"Sub-millisecond target not achieved\");\n    assert!(ops_per_second > 1000.0, \"Throughput too low: {:.2} ops/sec\", ops_per_second);\n    \n    println!(\"\\n🎉 Sub-millisecond performance validation PASSED!\");\n}\n\n/// Test concurrent sub-millisecond operations\n#[tokio::test]\nasync fn test_concurrent_minimal_operations() {\n    println!(\"🚀 Testing concurrent minimal operations...\");\n    \n    let concurrent_tasks = 50;\n    let operations_per_task = 20;\n    \n    let start_time = Instant::now();\n    let mut tasks = Vec::new();\n    \n    for task_id in 0..concurrent_tasks {\n        let task = tokio::spawn(async move {\n            let mut task_latencies = Vec::new();\n            \n            for _ in 0..operations_per_task {\n                let op_start = Instant::now();\n                let data = vec![0u8; 128];\n                let _result = process_minimal_data(data).await;\n                let latency = op_start.elapsed();\n                task_latencies.push(latency.as_micros() as u64);\n            }\n            \n            (task_id, task_latencies)\n        });\n        tasks.push(task);\n    }\n    \n    // Collect results\n    let mut all_latencies = Vec::new();\n    let mut successful_tasks = 0;\n    \n    for task in tasks {\n        if let Ok((task_id, mut latencies)) = task.await {\n            all_latencies.append(&mut latencies);\n            successful_tasks += 1;\n            \n            if task_id % 10 == 0 {\n                println!(\"  Task {} completed\", task_id);\n            }\n        }\n    }\n    \n    let total_time = start_time.elapsed();\n    \n    // Calculate statistics\n    all_latencies.sort();\n    let avg_latency = all_latencies.iter().sum::<u64>() / all_latencies.len() as u64;\n    let p95_latency = all_latencies[(all_latencies.len() * 95) / 100];\n    let total_operations = all_latencies.len();\n    let ops_per_second = total_operations as f64 / total_time.as_secs_f64();\n    \n    println!(\"\\n📊 Concurrent Performance Results:\");\n    println!(\"  Successful tasks: {}/{}\", successful_tasks, concurrent_tasks);\n    println!(\"  Total operations: {}\", total_operations);\n    println!(\"  Average latency: {}μs\", avg_latency);\n    println!(\"  P95 latency: {}μs\", p95_latency);\n    println!(\"  Total time: {:.2}ms\", total_time.as_millis());\n    println!(\"  Throughput: {:.2} ops/sec\", ops_per_second);\n    \n    // Validate concurrent performance\n    assert!(successful_tasks >= concurrent_tasks * 95 / 100, \"Too many failed tasks\");\n    assert!(avg_latency < 1500, \"Concurrent average latency too high: {}μs\", avg_latency);\n    assert!(ops_per_second > 500.0, \"Concurrent throughput too low: {:.2} ops/sec\", ops_per_second);\n    \n    if avg_latency < 1000 {\n        println!(\"  🎉 Concurrent sub-millisecond performance achieved!\");\n    } else {\n        println!(\"  📊 Concurrent performance: {}μs (reasonable for concurrent load)\", avg_latency);\n    }\n}\n\n/// Test sustained performance over time\n#[tokio::test]\nasync fn test_sustained_minimal_performance() {\n    println!(\"🚀 Testing sustained minimal performance...\");\n    \n    let duration_seconds = 5;\n    let target_ops_per_second = 1000;\n    let batch_size = 100;\n    \n    let start_time = Instant::now();\n    let mut total_operations = 0;\n    let mut all_latencies = Vec::new();\n    \n    while start_time.elapsed().as_secs() < duration_seconds {\n        let batch_start = Instant::now();\n        let mut batch_latencies = Vec::new();\n        \n        for _ in 0..batch_size {\n            let op_start = Instant::now();\n            let data = vec![0u8; 64];\n            let _result = process_minimal_data(data).await;\n            let latency = op_start.elapsed();\n            batch_latencies.push(latency.as_micros() as u64);\n        }\n        \n        all_latencies.extend(batch_latencies);\n        total_operations += batch_size;\n        \n        let batch_time = batch_start.elapsed();\n        let batch_ops_per_sec = batch_size as f64 / batch_time.as_secs_f64();\n        \n        if total_operations % 500 == 0 {\n            println!(\"  Operations: {}, Batch rate: {:.2} ops/sec\", total_operations, batch_ops_per_sec);\n        }\n        \n        // Small delay to prevent overwhelming the system\n        if batch_time.as_millis() < 10 {\n            sleep(Duration::from_millis(1)).await;\n        }\n    }\n    \n    let total_time = start_time.elapsed();\n    let sustained_ops_per_second = total_operations as f64 / total_time.as_secs_f64();\n    \n    // Calculate latency statistics\n    all_latencies.sort();\n    let avg_latency = all_latencies.iter().sum::<u64>() / all_latencies.len() as u64;\n    let p95_latency = all_latencies[(all_latencies.len() * 95) / 100];\n    \n    println!(\"\\n📊 Sustained Performance Results:\");\n    println!(\"  Duration: {:.2}s\", total_time.as_secs_f64());\n    println!(\"  Total operations: {}\", total_operations);\n    println!(\"  Sustained throughput: {:.2} ops/sec\", sustained_ops_per_second);\n    println!(\"  Average latency: {}μs\", avg_latency);\n    println!(\"  P95 latency: {}μs\", p95_latency);\n    \n    // Validate sustained performance\n    assert!(sustained_ops_per_second > target_ops_per_second as f64 * 0.8, \n        \"Sustained throughput too low: {:.2} ops/sec\", sustained_ops_per_second);\n    assert!(avg_latency < 2000, \"Sustained average latency too high: {}μs\", avg_latency);\n    \n    if avg_latency < 1000 {\n        println!(\"  🎉 Sustained sub-millisecond performance achieved!\");\n    } else {\n        println!(\"  📊 Sustained performance: {}μs (reasonable under load)\", avg_latency);\n    }\n}\n\n/// Minimal data processing function that simulates basic operations\nasync fn process_minimal_data(data: Vec<u8>) -> Vec<u8> {\n    // Simulate minimal processing without complex dependencies\n    let mut result = Vec::with_capacity(data.len() + 50);\n    \n    // Add a simple header\n    let header = format!(\"SIZE:{}\", data.len());\n    result.extend_from_slice(header.as_bytes());\n    result.push(b'|');\n    \n    // Add the original data\n    result.extend_from_slice(&data);\n    \n    // Minimal async yield to simulate async processing\n    tokio::task::yield_now().await;\n    \n    result\n}\n\n/// Test different payload sizes for performance characteristics\n#[tokio::test]\nasync fn test_payload_size_performance() {\n    println!(\"🚀 Testing payload size performance characteristics...\");\n    \n    let payload_sizes = vec![32, 64, 128, 256, 512, 1024, 2048];\n    let iterations_per_size = 500;\n    \n    println!(\"\\n📊 Payload Size Performance Analysis:\");\n    println!(\"Size (bytes) | Avg (μs) | P95 (μs) | P99 (μs) | Ops/sec | Sub-ms?\");\n    println!(\"-------------|----------|----------|----------|---------|--------\");\n    \n    for size in payload_sizes {\n        let mut latencies = Vec::new();\n        let start_time = Instant::now();\n        \n        for _ in 0..iterations_per_size {\n            let data = vec![0u8; size];\n            let op_start = Instant::now();\n            let _result = process_minimal_data(data).await;\n            let latency = op_start.elapsed();\n            latencies.push(latency.as_micros() as u64);\n        }\n        \n        let total_time = start_time.elapsed();\n        \n        // Calculate statistics\n        latencies.sort();\n        let avg_latency = latencies.iter().sum::<u64>() / latencies.len() as u64;\n        let p95_latency = latencies[(latencies.len() * 95) / 100];\n        let p99_latency = latencies[(latencies.len() * 99) / 100];\n        let ops_per_second = iterations_per_size as f64 / total_time.as_secs_f64();\n        let is_sub_ms = avg_latency < 1000;\n        \n        println!(\"{:>12} | {:>8} | {:>8} | {:>8} | {:>7.0} | {}\",\n            size, avg_latency, p95_latency, p99_latency, ops_per_second,\n            if is_sub_ms { \"✅ YES\" } else { \"❌ NO\" }\n        );\n        \n        // Validate that small payloads achieve sub-millisecond performance\n        if size <= 256 {\n            assert!(avg_latency < 1000, \n                \"Sub-millisecond target not met for {} bytes: {}μs\", size, avg_latency);\n        }\n    }\n    \n    println!(\"\\n🎉 Payload size performance analysis completed!\");\n}\n